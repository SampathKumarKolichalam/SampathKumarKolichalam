# Sampath Kumar Kolichalam

## About Me

ðŸ‘‹ Hi, I am Sampath Kumar Kolichalam, a Data Engineer with 3+ years of experience building scalable data pipelines, real-time ingestion systems, and cloud-native backend services. My work sits at the intersection of Big Data Engineering, Cloud/DevOps & Backend Microservices.

**Currently at JOBSNPROFILES LLC, I contribute to an AI-Powered Recruitment SaaS platform where I:**
- Built scalable batch pipelines using PySpark, Airflow, Hadoop, and ADF, processing 30K+ resumes/day.
- Developed real-time resume ingestion using Kafka + Spring Boot Microservices deployed on AKS.
- Integrated Ollama & Deep Seek LLMs to convert unstructured resumes into structured JSON formats.
- Implemented monitoring & observability with Azure Monitor, Log Analytics, and Power BI.
- Designed semantic search & matching workflows using Apache Solr, Embeddings, and Vector DB's (Qdrant DB).

**Beyond work, I have completed academic and personal projects:**
- Pneumonia Detection with Vision Transformers (ViT + CNN) â€“ achieved >90% accuracy.
- Smart Resume Analyzer (NLP + FastAPI) â€“ automated insights & job match scoring.
- House Price Prediction (ML + Flask) â€“ real-time property price estimation.
- IoT Smart Plant Watering System (Arduino + Sensors) â€“ automated irrigation with data-driven control.
- I enjoy solving engineering problems from Scalable Data Pipelines, Backend APIs, scalable cloud deployments, and real-time AI-driven analytics.

**Core Skills:**

- **Programming & Scripting:** Java, Python, SQL, Linux, Bash & Shell Scripting.
- **Databases & Storage:** MySQL, PostgreSQL, MongoDB, Spark SQL, Apache Solr, Delta Lake. 
- **Big Data Engineering:** Hadoop, PySpark, Airflow, Kafka, Databricks, Snowflake, ETL/ELT Workflows.
- **DevOps & Cloud:**  Microsoft Azure, AWS, Docker, Kubernetes, Git, GitHub Actions, CI/CD.
- **Applied AI & LLMs:** Prompt Engineering, Embeddings, Vector DB (Qdrant), Semantic Search, Multi Agents, LLMs, Gen AI.
- **Monitoring, Analytics & Visualization:** Azure Monitor, Azure Log Analytics, Microsoft Power BI.
- **Backend & APIs:** Spring Boot, Node.js, Microservices, REST/GraphQL, JWT, OAuth 2.0.
- **Tools & Practices:** Agile, Scrum, SDLC, JIRA, Pytest, DBT, Thunder Client, Version Control(Git).

---

## Education

**Kent State University, Ohio, USA**  
M.S. in Computer Science  
Aug 2023 â€“ Dec 2024  
GPA: 3.8/4.0

**Lingayaâ€™s Vidyapeeth, Delhi, India**  
B.Tech in Computer Science & Engineering  
Aug 2019 â€“ Jun 2023  
CGPA: 9.2/10

---

## Professional Experience

### JobsnProfiles LLC â€” Data Engineer  
Salt Lake City, UT | May 2024 â€“ Present

- Designed and optimized a batch resume parsing pipeline on a 40-node Hadoop cluster, processing 30K+ resumes/day with 25% higher throughput.
- Built a Kafka-based real-time ingestion system on AKS to power signups, job fairs, and optimizer workflows, handling 20K+ events/resumes per job fair.
- Developed and deployed Spring Boot microservices with MySQL, reducing authentication latency by 35% and improving RBAC-driven security across modules.
- Refactored Airflow DAGs and PySpark jobs to reduce task failures by 40% and increase cross-pipeline scheduling reliability.
- Implemented resume validation & deduplication logic using SQL and PySpark, improving data quality and match accuracy by 30%.
- Integrated semantic search workflows using Embeddings, Solr, and Qdrant Vector DB, improving recruiter match scoring and search relevance.
- Delivered end-to-end monitoring dashboards with Azure Monitor, Log Analytics, and Power BI, increasing pipeline observability and uptime by 45%.
- Collaborated with backend, AI, and data teams to support RAG workflows, embeddings-based models, and automated parsing pipelines.

---

### NITYA Software Solutions â€” Data Engineer 
Hyderabad, India | Jan 2022 â€“ Jul 2023

-  Built automated ETL pipelines using Azure Data Factory and SQL Server to streamline billing, payroll, and finance workflows across teams.
-  Improved invoice & payroll data quality by 35% through PySpark-based cleansing, validation rules, and anomaly detection scripts on Azure Databricks.
-  Automated daily ingestion workloads using Azure Functions, increasing data freshness and report accuracy by 40%.
- Optimized PySpark and SQL transformations for billing pipelines, improving dashboard query speed and load time by 30%.
- Developed Power BI dashboards for finance KPIs, reducing manual reporting dependency by 50% and improving decision-making.
- Enhanced data models using fact/dimension schemas, improving analytic query performance by 40%.
- Collaborated with analysts and backend teams in Agile sprints to improve KPIs, unify data definitions, and accelerate delivery with Azure DevOps.

---

### AI Walkers â€” Python Developer Intern  
Hyderabad, India | Aug 2021 â€“ Dec 2021

- Developed Python scripts using Pandas, NumPy, and SQL to automate data preparation tasks for course analytics and student activity reports.
- Built lightweight Flask REST APIs to deliver ML model outputs such as text classification and course-recommendation insights.
- Assisted in creating backend integrations for course content modules, improving load times and API responsiveness.
- Implemented basic ML pipelines for text classification, helping categorize course reviews and learner feedback.
- Supported the team in cleaning structured and unstructured datasets, improving dataset usability for internal NLP experiments.
- Collaborated with developers and content teams to enhance platform features, debug issues, and improve reliability during product updates.

---

## Projects

### JobsnProfiles Platform â€“ AI Powered Recruitment SaaS Platform  
**Role:** Data Engineer | JobsnProfiles | May 2024 â€“ Present  
**Tech Stack:** PySpark, Hadoop, Azure, MySQL, Airflow, Spring Boot, Power BI, LLM's, Semantic Search, Gen AI.

- AI-Powered Recruitment SaaS platform for candidate profiling, resume parsing, recruiter workflows & virtual job fairs. 
- Built scalable batch resume parsing pipeline using PySpark, Airflow, Hadoop & Azure Data Factory for bulk ingestion. 
- Developed real-time parsing pipeline with Kafka & Spring Boot microservices on AKS with secure REST APIs. 
- Designed multi-agent architecture for parsing text extraction, cleaning, sectioning, validation & deduplication. 
- Integrated Ollama & DeepSeek LLMs to convert resumes into structured JSON formats via downstream agents. 
- Stored raw resumes in Azure Blob, JSON in MySQL, metadata in MongoDB & semantic vectors in Solr/Qdrant. 
- Enabled monitoring with Azure Monitor, Log Analytics, and Power BI to track pipeline health and latency.

---

### Pneumonia Disease Detection â€“ AI/ML for Healthcare  
**Tech Stack:** TensorFlow, PyTorch, Vision Transformers, CNN, Flask, OpenCV, Docker.  
[GitHub Repository](https://github.com/K-Roshini-Reddy/Capstone---Team_2)  
[Demo Video](https://video.kent.edu/media/Capstone%20Project%20Demo/1_u6w5bck1)

- Achieved 90.65% accuracy with a Vision Transformer model on chest X-ray data.
- Reduced false positives by 25% compared to CNN benchmarks.
- Deployed real-time prediction API using Flask and Docker.
- Used OpenCV for data preprocessing and augmentation.

---

### Anna Books â€“ Accounting & Billing Platform  
**Role:** Data Engineer | NITYA Software Solutions | Jan 2022 â€“ Jul 2023  
**Tech Stack:** Python, PySpark, MySQL, PySpark, Power BI, Airflow, Azure, DevOps.

- Built ETL pipelines using Azure Data Factory and SQL Server to automate Billing and Payroll loads.
- Improved invoice data quality through PySpark cleansing and validation scripts on Azure Databricks.
- Automated daily ingestion jobs with Azure Functions to boost data freshness and report accuracy.
- Optimized billing and payroll data pipelines using PySpark and SQL, improving dashboard load speed.
- Created Power BI dashboards to help finance teams track key performance indicators (KPIs) and reduce manual reporting time.
- Collaborated in Agile sprints with analysts and developers to accelerate feature delivery using Azure DevOps.

---

### Smart Resume Analyzer â€“ AI & NLP Based Tool 
**Tech Stack:** Python, SpaCy, FastAPI, MongoDB, Streamlit, Flask, Docker.  
[GitHub Repository](https://github.com/SampathKumarKolichalam/Smart-Resume-Analysis-Using-NLP)

- Built NLP pipelines to extract structured fields from resumes.
- Designed and deployed FastAPI endpoints for resume parsing and scoring.
- Developed a Streamlit-based frontend for HR users.
- Deployed using Docker and persisted results in MongoDB.

---

## Certifications

- Spring Boot & Microservices Development â€“ Udemy.  
- AWS Developer Training â€“ LinkedIn Learning.  
- Microsoft Azure AI Essentials â€“ Microsoft. 
- Career Essentials in Software Development â€“ LinkedIn/Microsoft.
- Docker Foundations â€“ Docker, Inc.

---

## Languages

- English â€“ Professional Working Proficiency.  
- Hindi â€“ Limited Working Proficiency.  
- Telugu â€“ Native/Bilingual Proficiency.

---

## Interests

Cricket, Traveling, Cooking, AI/ML Exploration.

---

## GitHub Stats

![GitHub Stats](https://github-readme-stats.vercel.app/api?username=SampathKumarKolichalam&show_icons=true&theme=default)  
![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=SampathKumarKolichalam&layout=compact&theme=default)

---

## Contact

**Email:** [sampathkumarkolichalam@gmail.com](mailto:sampathkumarkolichalam@gmail.com)  
**LinkedIn:** [Sampath Kolichalam](https://www.linkedin.com/in/sampath-kumar-kolichalam-18b57b1ab/)  
**GitHub:** [@SampathKumarKolichalam](https://github.com/SampathKumarKolichalam)
